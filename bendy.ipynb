{
 "metadata": {
  "name": "",
  "signature": "sha256:3c273b7952b5877c3c9075fa2ccaa17a533ed36ecec1b3890f6f5f310ba376df"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Bendy: Wavetable Automaton Synthesis with Indirect Feedback\n",
      "\n",
      "Let's consider a cosmology in which all minds and everything we can perceive are very high-order emergent interactions between tiny elements. My work aims to engage this idea by constructing mathematical objects with complex dynamic behavior. Computers make it possible to simulate such objects and entangle them with the world of human sensory experience.\n",
      "\n",
      "The present work is about a software synthesizer called Bendy. Bendy is a modest attempt work with sound within this paradigm; I hope it can create novel sound objects and enable musical experiences. A first study using Bendy can be found [here](https://soundcloud.com/victorshepardson/bendy-1).\n",
      "\n",
      "## Synthesis\n",
      "\n",
      "####Wavetable Automaton\n",
      "\n",
      "Consider a multi-channel wavetable $w(s) \\in \\mathbb{R}^C$, where $C$ is the number of channels, $N$ is the length of the wavetable, and $s \\in [1, N]$ is the sample index. Let $w_t$ be the wavetable at time $t$, and let a transition function $\\Delta$ parameterized by $\\theta$ and some initial condition $w_0$ define a time series of wavetables: $$w_t = \\Delta_\\theta(w_{t-1})$$ \n",
      "\n",
      "Possible $\\Delta$ include local convolution as in Karplus-Strong$^1$ or discrete linear automata as in LASy$^2$. I propose a real-valued automaton built from the following components:\n",
      "\n",
      "- Local convolution with kernel $\\theta_c$ $$w' = \\theta_c * w$$\n",
      "- Domain distortion with magnitude $\\theta_w$ $$w''(s) = w'(s+\\theta_w\\delta(w(s)))$$\n",
      "- Nonlinear squashing with feedback $\\theta_{fb}$ and bias $\\theta_b$ $$w''' = \\sigma(\\theta_{fb}w''+\\theta_b)$$\n",
      "- Feedforward with amount $\\theta_{ff} \\in [0,1]$ $$w'''' = \\mathrm{mix}(w''', w, \\theta_{ff})$$\n",
      "\n",
      "Intuitively, the convolution acts as a low-pass filter. This is complemented by the domain distortion $\\delta$ which can introduce transients and high harmonics. The squashing function $\\sigma$ restricts the signal to an appropriate dynamic range and supplies an additional nonlinearity. Finally, the feedforward stage acts an overall rate of change knob: empirically, it often directly controls the rate at which patterns occur in the output. See the implementation for more details about $\\theta_c$, $\\delta$ and $\\sigma$.\n",
      "\n",
      "####Independent Read and Update\n",
      "\n",
      "It would be prohibitively expensive to update the entire automaton at sample rate. I take the same approach as LASy$^2$ which is to loop through the automaton at sample rate computing one new position per sample of audio. In LASy, the newly computed value is simply used as output. This forces pitch to be determined by the length of the automaton. One could decouple the update rate from the read rate at the risk of introducing artifacts related to the automaton size. To minimize such artifacts, I interpolate the last two automaton states such that the \"update head\" of the automaton is always excluded from the current wavetable. \n",
      "\n",
      "When read rate is greater than update rate, there is still risk of aliasing high frequencies. To combat this I introduce a brute-force oversampling parameter on the wavetable. I have gotten good results using a ~3000 sample wavetable at a sample rate of 96kHz with 4x oversampling.\n",
      "\n",
      "####Indirect Feedback\n",
      "\n",
      "The idea is to map a random subset of the spectral dynamics of the automaton back onto its input parameters. To do this I define a real-time signal-rate joint feature extractor $F(X)$ for a set of signals $X$. Let $v(x)$ be a spectral envelope follower defined as the log of the moving RMS average of a constant-Q filter bank on a signal $x$. Let $v'$ be the concatenation of $v(x)$ over all $x \\in X$. Finally, let $M$ be a weight matrix defining a linear transformation from the concatenated spectral envelopes to some number of outputs, and $\\sigma$ be a squashing function mapping the real line to an appropriate range. Then: $$F(X) = \\sigma(Mv')$$\n",
      "\n",
      "To make things more concrete, consider a stereo wavetable automaton. Let $X$ be the set of two signals generated by reading the two channels of the wavetable independently at rates $f_L$ and $f_R$. Using 8-channel filter banks we have a 16-channel input feature which is mapped to 2 output features by the 2 x 16 matrix $M$. These two output features are squashed to the range $[-1, 1]$ using the hyperbolic tangent as $\\sigma$. Let the two elements of $F(X)$ be called $h_L$ and $h_R$. Introducing parameters $f^0_R$, $f^0_L$ which take values between 0 and 20kHz we close the loop: $$f_L = f^0_L h_L$$ $$f_R = f^0_R h_R$$\n",
      "\n",
      "This mechanism allows timbre to influence pitch. Feeding the output back as the bias term likewise allows pitch to influence timbre. Rhythm, harmony and melody are emergent propeties of this interaction in time. As a result, Bendy can synthesize a rich class of sound objects.\n",
      "\n",
      "## Control\n",
      "\n",
      "####Microphone Input\n",
      "\n",
      "Direct acoustic input can be an expressive control. There are two non-exclusive modes of signal input to Bendy: as bias parameter to the wavetable automaton, or as input to the feature extractor controlling indirect feedback. As a bias, an input signal can affect timbre and dynamics. As an input to the feature detector it can affect pitch. \n",
      "\n",
      "####Randomly Sampling Parameter Space\n",
      "\n",
      "Bendy has a large number of control parameters, the effects and interdependencies of which are not obvious. As a simple way to explore the parameter space, I have implemented random sampling according to a hand-constructed probability distribution. Each parameter is drawn independently from an appropriate ad-hoc distribution. For example, values which respresent frequencies are drawn from a uniform distribution over 10 octaves of log frequency.\n",
      "\n",
      "## Implementation\n",
      "\n",
      "Bendy has been implemented as a vanilla Max/MSP patch using the gen~ object to write the core synthesizer. The implementation given here only has GUI control, but it would be straightforward to add control by MIDI, OSC, Live, or Max. On my laptop the MSP implementation consumes about 15% CPU at 44.1kHz with no oversampling up to about 50% CPU at 96kHz with 4x oversampling. Future work may include a performance-conscious implementation in C++.\n",
      "\n",
      "## Future Work\n",
      "\n",
      "The 1-D automaton used as a wavetable in this work could also be interpreted as a harmonic spectrum by taking the DFT of the automaton before reading it as a wavetable. I conjecture that such an approach might be less prone to realistic transients but more prone to interesting timbral dynamics. If the two turn out to complement one another it could be interesting to cascade them with the spectral automaton acting as bias to the wavetable automaton or vice-versa. The spectral version might also confer the advantage of perfect antialiasing -- any partials above the Nyquist rate could be set to zero before the DFT is applied.\n",
      "\n",
      "In this general framework, the transition function $\\Delta$ and feature extractor $F$ could each be replaced by machine learning techniques. For example, $\\Delta$ could be a recurrent neural network trained to predict the waveform of natural instruments. $F$ could be a feedforward neural network trained to discriminate between genres of music with a final random layer on top.\n",
      "\n",
      "The mapping from features to fundamental frequencies could be extended to the automaton parameters as well. This could move more parameters into the feature extraction stage and enable new kinds of dynamic behavior.\n",
      "\n",
      "Machine learning could also be used to define a low-dimensional parameter space. A labeled dataset associating parameter vectors with audio signal could be obtained by sampling the parameter space and running the synth. Then, a low dimensional embedding for the audio could be found with e.g. PCA on a hand constructed audio feature or a deep autoencoder. The embedding could be used to interpolate the associated parameter vectors in the low dimensional space.\n",
      "\n",
      "Initial conditions have not been explored much as a parameter. It could be interesting to search over the intial wavetable state with other parameters fixed. It would also be very useful to store/recall wavetable states as a point of control.\n",
      "\n",
      "The computationally expensive elements of Bendy are massively parallel and potentially insensitive to latency in the tens of milliseconds. This opens the door to GPU acceleration. It will be interesting to see how the character of this technique can change with orders of magnitude more voices or orders of magnitude higher resolution.\n",
      "\n",
      "## References\n",
      "\n",
      "1. Karplus, K., & Strong, A. (1983). Digital synthesis of plucked-string and drum timbres. Computer Music Journal, 43-55.\n",
      "2. Chareyron, J. (1990). Digital synthesis of self-modifying waveforms by means of linear automata. Computer Music Journal, 25-41. Chicago\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}